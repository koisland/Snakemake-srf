from typing import Any
from os.path import join, splitext, abspath, dirname


LOG_DIR = config.get("log_dir", "logs")
BMK_DIR = config.get("benchmark_dir", "benchmarks")
OUTPUT_DIR = config.get("output_dir", "results")


def get_parameters() -> tuple[dict[str, Any], dict[str, Any]]:
    samples = {}
    parameters = {}

    for sm, cfg in config["samples"].items():
        if cfg.get("input_dir"):
            infiles = cfg["input_dir"]
        elif cfg.get("input_files"):
            infiles = cfg["input_files"]
        else:
            raise FileNotFoundError("No input directory of files provided.")

        parameters[sm] = cfg["parameters"]
        samples[sm] = infiles

    return samples, parameters


SAMPLES, PARAMS = get_parameters()


wildcard_constraints:
    sm="|".join(SAMPLES.keys()),
    fname=r"[^\/]+",


rule compile_srf:
    output:
        directory(join(OUTPUT_DIR, "srf")),
    log:
        abspath(join(LOG_DIR, "compile_srf.log")),
    shell:
        """
        git clone https://github.com/lh3/srf {output} 2> {log}
        cd {output} && make &>> {log}
        """


rule compile_trf:
    output:
        bn=join(OUTPUT_DIR, "TRF-mod", "trf-mod"),
    log:
        abspath(join(LOG_DIR, "compile_trf.log")),
    params:
        outdir=lambda wc, output: dirname(output[0]),
    shell:
        """
        git clone https://github.com/lh3/TRF-mod {params.outdir} 2> {log}
        cd {params.outdir} && make -f compile.mak &>> {log}
        """


checkpoint get_fa_srf:
    input:
        infile=lambda wc: SAMPLES[wc.sm],
    output:
        outdir=temp(directory(join(OUTPUT_DIR, "{sm}", "fasta"))),
    log:
        join(LOG_DIR, "get_fa_srf_{sm}.log"),
    conda:
        "envs/tools.yaml"
    shell:
        """
        mkdir -p {output}
        # Get all non-hidden files.
        for file in $(find {input.infile} -mindepth 1 -maxdepth 1 -not -path '*/.*'); do
            # https://tldp.org/LDP/LG/issue18/bash.html 
            new_fname={output.outdir}/$(basename "${{file%%.*}}")".fa"
            if [[ ${{file}} == *fasta.gz || ${{file}} == *fa.gz ]]; then
                zcat ${{file}} > ${{new_fname}} 2>> {log}
            elif [[ ${{file}} == *.fasta || ${{file}} == *.fa ]]; then
                ln -s $(realpath ${{file}}) ${{new_fname}} 2>> {log}
            fi
        done
        """


# We group multiple commands because multiple rules slows DAG construction considerably.
rule find_satellites:
    input:
        bn_srf_dir=rules.compile_srf.output,
        bn_trf=rules.compile_trf.output.bn,
        seq=join(OUTPUT_DIR, "{sm}", "fasta", "{fname}.fa"),
    output:
        kmer_counts=join(OUTPUT_DIR, "{sm}", "{fname}", "count.txt"),
        motifs=join(OUTPUT_DIR, "{sm}", "{fname}", "srf.fa"),
        monomers=join(OUTPUT_DIR, "{sm}", "{fname}", "monomers.tsv"),
        paf=join(OUTPUT_DIR, "{sm}", "{fname}", "srf.paf"),
        enlong_contigs=join(OUTPUT_DIR, "{sm}", "{fname}", "srf_enlong.fa"),
        bed=join(OUTPUT_DIR, "{sm}", "{fname}", "srf.bed"),
    threads: config.get("threads", 16)
    params:
        output_prefix=lambda wc, output: splitext(output.kmer_counts)[0],
        tmp_dir=lambda wc, output: join(dirname(output.kmer_counts), "temp"),
        # Kmer size.
        k=lambda wc: PARAMS[wc.sm].get("kmer_size", 151),
        # Exclude kmers occurring less than n times.
        ci=lambda wc: PARAMS[wc.sm].get("exclude_kmers_lt_n", 3),
        # Maximal value of counter.
        cs=100_000,
        max_secondary_alns=lambda wc: PARAMS[wc.sm].get(
            "mm2_max_secondary_alns", 1_000_000
        ),
        ignore_minimizers_n=lambda wc: PARAMS[wc.sm].get(
            "mm2_ignore_minimizers_n", 1000
        ),
        aln_bandwidth=lambda wc: PARAMS[wc.sm].get("mm2_aln_bandwidth", "100,100"),
    resources:
        mem=config.get("mem", "20GB"),
    log:
        join(LOG_DIR, "find_satellites_{sm}_{fname}.log"),
    benchmark:
        join(BMK_DIR, "find_satellites_{sm}_{fname}.txt")
    conda:
        "envs/tools.yaml"
    shell:
        """
        # Count kmers.
        mkdir -p {params.tmp_dir}
        kmc -fm -k{params.k} -t{threads} \
            -ci{params.ci} -cs{params.cs} \
            {input.seq} {params.output_prefix} {params.tmp_dir} &> {log}
        kmc_tools transform {params.output_prefix} dump {output.kmer_counts} &>> {log}
        rmdir {params.tmp_dir}
        # Get HORs
        {{ ./{input.bn_srf_dir}/srf -p prefix {output.kmer_counts} || true ;}} > {output.motifs} 2>> {log}
        rm -f core*
        # Get monomers with trf
        if [ -s "{output.motifs}" ]; then
            ./{input.bn_trf} {output.motifs} | awk -v OFS="\\t" '{{ print "{wildcards.fname}", $0 }}' > {output.monomers} 2>> {log}
        fi
        touch {output.monomers}
        # Enlong and map to seq.
        ./{input.bn_srf_dir}/srfutils.js enlong {output.motifs} > {output.enlong_contigs} 2>> {log}
        minimap2 -c \
            -N{params.max_secondary_alns} \
            -f{params.ignore_minimizers_n} \
            -r{params.aln_bandwidth} \
            -t{threads} \
            {output.enlong_contigs} {input.seq} > {output.paf} 2>> {log}
        {{ ./{input.bn_srf_dir}/srfutils.js paf2bed {output.paf} | sort -k 1,1 -k2,2n ;}} > {output.bed} 2>> {log}
        """


def srf_output(wc):
    outdir = checkpoints.get_fa_srf.get(**wc).output[0]
    fnames = glob_wildcards(join(outdir, "{fname}.fa")).fname
    return expand(rules.find_satellites.output.bed, sm=wc.sm, fname=fnames)


def trf_output(wc):
    outdir = checkpoints.get_fa_srf.get(**wc).output[0]
    fnames = glob_wildcards(join(outdir, "{fname}.fa")).fname
    return expand(rules.find_satellites.output.monomers, sm=wc.sm, fname=fnames)


rule merge_files_n_cleanup:
    input:
        bed=srf_output,
        monomers=trf_output,
    output:
        bed=join(OUTPUT_DIR, "{sm}", "srf.bed"),
        monomers=join(OUTPUT_DIR, "{sm}", "monomers.tsv"),
    shell:
        """
        sort -k1,1 -k2,2n {input.bed} > {output.bed}
        sort -k1,1 {input.monomers} > {output.monomers}
        """


rule all:
    input:
        expand(rules.merge_files_n_cleanup.output, sm=SAMPLES),
    default_target: True
